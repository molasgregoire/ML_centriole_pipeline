{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "#pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "#functions file\n",
    "from functions import *\n",
    "#counting time\n",
    "import time\n",
    "\n",
    "from os import listdir \n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1bff1c72d90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SEED FOR RANDOM PROCESS\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note, the problematic images were removed\n",
    "### PARAMETERS\n",
    "super_epoch = 2         # number of iteration over ALL images\n",
    "epoch = 5               # number of iteration for one image\n",
    "gt_sensitivity = 0.85   # ground truth sensitivity (between 0 and 1, high value recommended)\n",
    "thr_permissivity = 0.005#-> proportion of pixel kept in the image by quantile selction (foreground selection)\n",
    "splitting_ratio = 0.8   # splitting ratio for train/test splitting\n",
    "batch_size = 100        # batch size for NN training\n",
    "learning_rate = 1e-3    # learning rate for NN training (1e-5 stabilize quite fast, let test with 1e-6)\n",
    "use_weight = True       #if true, the model will take in account the imbalance between true/false values within an image\n",
    "                        \n",
    "save_name = 'models/new_model' # the name for the file saved at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the file containing the positions for each centriole (csv)\n",
    "data = pd.read_csv(\"data/annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import images and the corresponding names\n",
    "## Load using channels\n",
    "channels = [0,1,2]\n",
    "#images,names = loadAllCtrImages(channels=channels, format_=\"tif\", path = path)\n",
    "\n",
    "print( 'number of images ' + str(len(images)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images 25\n"
     ]
    }
   ],
   "source": [
    "## load using a single folder (a single type of fluorescence)\n",
    "# example with CP110\n",
    "path = 'data/RPE1wt_CP110+GTU88+PCNT_2/CP110/tif'\n",
    "\n",
    "images = []\n",
    "names = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "for n in names:\n",
    "    images.append( cv.imread( path + '/' + n , cv.IMREAD_UNCHANGED) )\n",
    "\n",
    "names = [n[:-4] for n in names]\n",
    "\n",
    "print( 'number of images ' + str(len(images)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment if you want to use a certain number of random images in the list\n",
    "'''\n",
    "spl_nb = 20\n",
    "\n",
    "indexes_spl = [ i for i in range(len(images)) ]\n",
    "np.random.shuffle( indexes_spl )\n",
    "\n",
    "spl_images = []\n",
    "spl_names = []\n",
    "\n",
    "for i in indexes_spl[:spl_nb]:\n",
    "    spl_images.append( images[i] )\n",
    "    spl_names.append( names[i] )\n",
    "    \n",
    "images = spl_images\n",
    "names = spl_names\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the ground truth \n",
    "images_gt = groundTruthCtr( normalizeImages(images), names , data , 28 ,gt_sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OUR NEURAL NETWORK\n",
    "\n",
    "# device setting\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# class -> you can modify it (expect input/output) but if you do so, then you'd need to use the same for predictions\n",
    "class Pixel14(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(2, 21, kernel_size=2)\n",
    "        self.conv2 = torch.nn.Conv2d(21, 42, kernel_size=2)\n",
    "        n = 168\n",
    "        self.fc1 = torch.nn.Linear(168,n,bias=True)\n",
    "        self.fc2 = torch.nn.Linear(n,n,bias=True)\n",
    "        self.fc3 = torch.nn.Linear(n,n,bias=True)\n",
    "        self.fc4 = torch.nn.Linear(n,n,bias=True)\n",
    "        self.fc5 = torch.nn.Linear(n,n,bias=True)\n",
    "        # out layer\n",
    "        self.fcOut = torch.nn.Linear(n, 1,bias=True)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        relu = torch.nn.functional.relu\n",
    "        max_pool2d = torch.nn.functional.max_pool2d\n",
    "        # convolutions\n",
    "        x = relu(max_pool2d(self.conv1(x),2))\n",
    "        x = relu(max_pool2d(self.conv2(x),2))\n",
    "        #flatten\n",
    "        x = x.view(-1,168)\n",
    "        # linear layers\n",
    "        x = relu(self.fc1(x))\n",
    "        x = relu(self.fc2(x))\n",
    "        x = relu(self.fc3(x))\n",
    "        x = relu(self.fc4(x))\n",
    "        x = relu(self.fc5(x))\n",
    "        \n",
    "        # out layer\n",
    "        x = self.fcOut(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "#create NN object and asscoiated items for training\n",
    "model = Pixel14().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image normalization\n",
      "ground truth generation\n",
      "Iterations start here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gr√©goire\\Documents\\GitHub\\ML_centriole_clean\\functions.py:466: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  tensor_x = torch.Tensor([np.array( [i[0] , sobelization(i[0]) ]) for i in tuples_test]) # transform to torch tensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch 0 | mean criterion: 3.34745\n",
      "Epoch 1 | mean criterion: 2.42740\n"
     ]
    }
   ],
   "source": [
    "train_complete_pixel14( images , names, data ,\n",
    "                  model, optimizer,\n",
    "                  super_epoch, epoch, gt_sensitivity, thr_permissivity,\n",
    "                  splitting_ratio, batch_size, learning_rate, use_weight,\n",
    "                  save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best threshold for predictions ! (to use it later)\n",
    "t,p,f,r = findBestThr( images, names, data, model, thr_permissivity , step=0.05,  max_ = 1, min_ =0 )\n",
    "print( 'the best found threshold for prediction is : ',t )\n",
    "print( 'precision = ',p,' f1 = ',f,' recall ',r )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
