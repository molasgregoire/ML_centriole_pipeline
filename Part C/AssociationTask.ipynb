{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "There are 4 registered models for 'StarDist2D':\n",
      "\n",
      "Name                  Alias(es)\n",
      "────                  ─────────\n",
      "'2D_versatile_fluo'   'Versatile (fluorescent nuclei)'\n",
      "'2D_versatile_he'     'Versatile (H&E nuclei)'\n",
      "'2D_paper_dsb2018'    'DSB 2018 (from StarDist 2D paper)'\n",
      "'2D_demo'             None\n",
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "#Import all utility functions and required libraries\n",
    "from AssociationTask import *\n",
    "\n",
    "#Initializes display settings\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths definition and sample selection\n",
    "Define paths to images and predictions .csv and load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter path to images\n",
    "PATH = \"../data/\"\n",
    "#Prediction file path & datafile name\n",
    "PREDICTION_PATH = \"\"\n",
    "PREDICTION_NAME = \"CEP63_final_test.csv\"\n",
    "#Output path\n",
    "OUTPUT_PATH=\"\"\n",
    "#Name of ouput file\n",
    "OUTPUT_NAME = \"Association\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter channel 0, 1, 2 as int\n",
    "channel = 1\n",
    "#Enter id of images as list of two int in [0,1,2]\n",
    "id = [1,2]\n",
    "#Marker 1, 2 or 3 for centrioles\n",
    "mkr = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load images names and path\n",
    "IMG_Paths = generatePaths(channel, id, path=PATH)\n",
    "IMG_Names = generateNames(channel, id, path=PATH)\n",
    "\n",
    "Ncl_Path = IMG_Paths[0][0]\n",
    "Ncl_Name = IMG_Names[0]\n",
    "\n",
    "Ctr_Path = IMG_Paths[0][mkr]\n",
    "Ctr_Name = IMG_Names[mkr]\n",
    "\n",
    "FileName = IMG_Paths[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load centrioles dataframe and centrioles prediction for the corresponding image\n",
    "CTR_df = pd.read_csv(PREDICTION_PATH + PREDICTION_NAME)\n",
    "Ctr_df = CTR_df[CTR_df['image_name'] == Ctr_Name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define image to be processed by nucleus detection algorithm\n",
    "raw = plt.imread(Ncl_Path, cv.IMREAD_UNCHANGED)\n",
    "raw = raw.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Block\n",
    "Operates prediction of Nuclei detection and retrieve results for the association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9953, 0.3997, 0.9921, 0.9964, 0.9459, 0.9905, 0.9997, 0.9396, 1.0000,\n",
       "         0.9997, 1.0000, 0.9999, 0.9947, 1.0000, 0.9956, 0.9914, 1.0000, 0.9564,\n",
       "         1.0000, 0.9951, 0.9994, 0.8564, 0.9996, 1.0000, 0.9999, 0.9980, 0.8617,\n",
       "         1.0000, 0.9735, 0.8339, 0.8480, 0.9553, 0.9935],\n",
       "        grad_fn=<MaxBackward0>),\n",
       " tensor([1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 2, 1, 1, 0, 0]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute gradients in x and y directions using the Sobel mask\n",
    "grad_x = cv.Sobel(raw,ddepth=-1,dx=1,dy=0,ksize=31)\n",
    "grad_y = cv.Sobel(raw,ddepth=-1,dx=0,dy=1,ksize=31)\n",
    "grad_mag = np.sqrt(np.power(grad_x,2) + np.power(grad_y,2))\n",
    "grad_scaled = grad_mag/np.max(grad_mag)*np.max(raw)\n",
    "\n",
    "# Scale\n",
    "images = [grad_scaled, grad_scaled+raw, raw]\n",
    "resized = []\n",
    "\n",
    "for image in images:\n",
    "    image = cv.resize(image, (256,256))\n",
    "    resized.append(image)\n",
    "        \n",
    "# Run Stardist\n",
    "stack = []\n",
    "for img in resized:\n",
    "    labels, infos = model.predict_instances(normalize(img))\n",
    "    stack.append(labels)\n",
    "    points = infos['points']\n",
    "    prob = infos['prob']\n",
    "        \n",
    "attention_mask = np.sum(np.array(stack),axis = 0)\n",
    "blobs = measure.label(attention_mask>1)\n",
    "    \n",
    "# Add border\n",
    "add = 50\n",
    "\n",
    "scalled_gt = cv.copyMakeBorder(resized[-1], add, add, add, add, cv.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "mask = cv.copyMakeBorder(blobs, add, add, add, add, cv.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "output = cv.copyMakeBorder(labels, add, add, add, add, cv.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "    \n",
    "# define size of data\n",
    "size = 64\n",
    "e = int(size/2)\n",
    "    \n",
    "all_ = []\n",
    "for x,y,p in zip(points[:,0], points[:,1], prob[:]):\n",
    "        \n",
    "    # Compensate border \n",
    "    x += add\n",
    "    y += add\n",
    "        \n",
    "    nuc = scalled_gt[x-e:x+e,y-e:y+e]\n",
    "    crop = mask[x-e:x+e,y-e:y+e]\n",
    "    out = output[x-e:x+e,y-e:y+e]\n",
    "        \n",
    "    nuc_mag = crop[32,32]\n",
    "    out_mag = out[32,32]\n",
    "        \n",
    "    filtered = nuc*((crop == nuc_mag)+0.25*(crop!=nuc_mag).astype(int))\n",
    "    out = out*(out==out_mag)\n",
    "    \n",
    "    filtered = (filtered-filtered.mean())/filtered.std()\n",
    "    out = (out-out.mean())/out.std()\n",
    "    \n",
    "    tmp = np.array([filtered,out])\n",
    "    all_.append(tmp)\n",
    "    \n",
    "input_ = torch.from_numpy(np.array(all_)).float()\n",
    "input_.shape\n",
    "\n",
    "output = model1(input_)\n",
    "value,idx = output.max(1)\n",
    "value,idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assignment process\n",
    "label_list = np.unique(labels)\n",
    "_, _, _, CtrDic = AssingCtr(Ctr_df, labels, infos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .csv file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create ouput dataframe and add arrays to fill\n",
    "Output_df = Ctr_df[['image_name', 'x', 'y', 'score']].rename(columns={'x':'ctr_x', 'y':'ctr_y', 'score':'ctr_score'})\n",
    "nucleus_id = np.full([len(Ctr_df.x), 1], -1)\n",
    "ncl_x = np.full([len(Ctr_df.x),1], -1)\n",
    "ncl_y = np.full([len(Ctr_df.x),1], -1)\n",
    "Sncl_score = np.zeros([len(Ctr_df.x),1])\n",
    "ncl_class = np.full([len(Ctr_df.x), 1], -1)\n",
    "class_conf = np.zeros([len(Ctr_df.x), 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(zip(Ctr_df.x, Ctr_df.y)):\n",
    "    for k, v in CtrDic.items():\n",
    "        for ctr in v:\n",
    "            if ctr[0] == x and ctr[1] == y:\n",
    "                nucleus_id[i] = k\n",
    "                ncl_x[i] = infos[\"points\"][k-1][1]*8\n",
    "                ncl_y[i] = infos[\"points\"][k-1][0]*8\n",
    "                Sncl_score[i] = infos[\"prob\"][k-1]\n",
    "                ncl_class[i] = idx[k-1]\n",
    "                class_conf[i] = value[k-1].item()\n",
    "\n",
    "Output_df['nucleus_id'] = nucleus_id\n",
    "Output_df['ncl_x'] = ncl_x\n",
    "Output_df['ncl_y'] = ncl_y\n",
    "Output_df['Stardist_ncl_score'] = Sncl_score\n",
    "Output_df['nucleus_class'] = ncl_class\n",
    "Output_df['class_confidence'] = class_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output_df.to_csv(OUTPUT_PATH+OUTPUT_NAME+\".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "047216272baf659d589fe174042d5d59964a90c325689701c56ac0738251c266"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
